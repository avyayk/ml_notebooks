{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyayk/ml_notebooks/blob/main/maskClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqDFkRi5Wmf7"
      },
      "source": [
        "#Fine-Tuning VGG11 Image Classifier to Recognize Particular Image Features\n",
        "\n",
        "In this project, we will fine-tune a Convolutional NN image classification model to classify whether people in the images are wearing masks (task-specific function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkd7-FTWxqd"
      },
      "source": [
        "##Step 1: Set up the environment \n",
        "\n",
        "'Runtime' > 'Change runtime type' > 'Hardware accelerator' > 'GPU'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NahWG6KiTm02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbb65a1-c188-4858-80f1-2fc4973893e5"
      },
      "source": [
        "## Requisite Imports ## \n",
        "\n",
        "# Utilities ( stay consistent between Python 2 & 3 )\n",
        "from __future__ import print_function \n",
        "from __future__ import division\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn # Neural Networks\n",
        "import torch.optim as optim # Optimizers\n",
        "\n",
        "# NumPy for data handling\n",
        "import numpy as np\n",
        "\n",
        "# Torchvision for image datasets and manipulation\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# Pyplot to generate plots (unused)\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# More utilities\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Print the versions of PyTorch and Torchvision used in this project\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.13.1+cu116\n",
            "Torchvision Version:  0.14.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIH6_gl1Xij4"
      },
      "source": [
        "##Step 2: Set up the training and validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci76Zku_aYKf"
      },
      "source": [
        "Data Source: https://drive.google.com/drive/folders/1J7zq8j03w1R4DzcIFiLIDuOgCxlOeugy?usp=sharing \n",
        "\n",
        "Copy into your own Google Drive and set the filePath accordingly & folder names accordingly. In this notebook, I have changed the folder names to 'trainingData', 'validationData', and 'testData' (used later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-NHUUKCZ_T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b63e2a-abf2-464a-f550-59aa301dd582"
      },
      "source": [
        "## Mount Google Drive ##\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPTDG41HbnmG"
      },
      "source": [
        "# Extract the image data from the zipped imageset (only do this once)\n",
        "### WRONG FILEPATH! \n",
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/gdrive/My Drive/mask_classification/mask_image_set.zip', 'r') as zipObject:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObject.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD8xmIBAXb_t"
      },
      "source": [
        "## Some definitions... ##\n",
        "\n",
        "# directoryPath to imageset of people wearing masks (and lambda for convenience)\n",
        "## NOTE: This is MY directoryPath, not necessarily yours\n",
        "directoryPath = '/content/gdrive/My Drive/mask_image_set/mask_image_set'\n",
        "get_folder_path = lambda fileFolder : os.path.join( directoryPath, fileFolder )\n",
        "\n",
        "# NUMBER_OF_CLASSES in the dataset (masked / non-masked)\n",
        "NUMBER_OF_CLASSES = 2\n",
        "\n",
        "# Training batch size (# of samples processed before the model is updated)\n",
        "## Change depending on how much memory we have\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Number of training epochs\n",
        "NUMBER_OF_EPOCHS = 25\n",
        "\n",
        "# Only update reshaped layer parameters (True); otherwise finetune the entire model (False)\n",
        "FEATURE_EXTRACTION_ON = True\n",
        "\n",
        "# Image size for the network input (we will perform a square resize)\n",
        "IMAGE_SIZE = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5v47HS5gNlS"
      },
      "source": [
        "In PyTorch, data is organized using DataLoader and Dataset modules\n",
        "\n",
        "Datasets: the abstract structure that organize all the images and labels\n",
        "\n",
        "Dataloader: the generator to yield data batch for model training at each step##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8dgPnaGgA4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24b3e1f-73ac-4f4e-f8d4-3c6be5fb0d1f"
      },
      "source": [
        "## Input the 'trainingData' and 'validationData' from their respective folders ##\n",
        "\n",
        "# Common mean and standard deviation selection for ImageNet normalization (for DataTransforms)\n",
        "normalizationMean, normalizationSTD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "# DataTransforms for trainingData and validationData\n",
        "DataTransforms = {\n",
        "    'trainingData': transforms.Compose( [\n",
        "        transforms.RandomResizedCrop( IMAGE_SIZE ), # Random Crop\n",
        "        transforms.RandomHorizontalFlip(), # Random Horizontal Flip\n",
        "        transforms.ToTensor(), # Conversion to Tensor\n",
        "        transforms.Normalize( normalizationMean, normalizationSTD )\n",
        "    ]),\n",
        "\n",
        "    'validationData': transforms.Compose( [\n",
        "        transforms.Resize( IMAGE_SIZE ),\n",
        "        transforms.CenterCrop( IMAGE_SIZE ),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize( normalizationMean, normalizationSTD )\n",
        "    ])\n",
        "}\n",
        "\n",
        "# FOLDER_NAMES to eliminate redundancy moving forward\n",
        "FOLDER_NAMES = ('trainingData', 'validationData')\n",
        "\n",
        "# Map our DataTransforms and create trainingData and validationData datasets\n",
        "ImageDatasets = { \n",
        "    currentFolder: datasets.ImageFolder( get_folder_path( currentFolder ), \\\n",
        "                                      DataTransforms[ currentFolder ] ) \\\n",
        "    for currentFolder in FOLDER_NAMES\n",
        "}\n",
        "\n",
        "\n",
        "# Create trainingData and validationData DataLoaders\n",
        "ImageDataLoaders = {\n",
        "    currentFolder: torch.utils.data.DataLoader( ImageDatasets[ currentFolder ], \\\n",
        "                                             batch_size = BATCH_SIZE, \\\n",
        "                                             shuffle = True, \\\n",
        "                                             num_workers = 4 ) \\\n",
        "                    for currentFolder in FOLDER_NAMES\n",
        "}\n",
        "\n",
        "# Detect if we have a GPU available, and set the RuntimeDevice accordingly\n",
        "RuntimeDevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzG032auZAZQ"
      },
      "source": [
        "##Step 3: Model Initialization\n",
        "There are lots of deep models with hundreds of layers trained on Imagenet, a large dataset including images of 1000 classes. We consider models trained on this large dataset have already gained plenty of visual knowledge, therefore, after we use our own data to finetune model, hopefully the model will learn to deal with our new task combining knowledge gained from task-specific new data and its previous visual knowledge trained from Imagenet.\n",
        "\n",
        "To initialize the model, we can take advantage of TorchVision, a package saving plenty of deep model parameters. As mentioned above, the model is learned to classify 1000 classes. Here we only want to classify two classes, therefore, after downloading the model, we will change the dimension of the last layer to two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN6ctIeca_mq"
      },
      "source": [
        "# If FEATURE_EXTRACTION_ON, then this function will freeze all layers except the last layer\n",
        "def set_gradient_requirements( model, feature_extraction_on = FEATURE_EXTRACTION_ON ):\n",
        "    if feature_extraction_on:\n",
        "        for parameter in model.parameters():\n",
        "            parameter.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX6fPI2GadH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bee12f-e81f-48fc-8823-3e5c448b4dd4"
      },
      "source": [
        "# Our pre-trained CNN model that has been fine-tuned; we are using a VGG11 image classifier \n",
        "ImageClassifier = models.vgg11_bn( pretrained = True ) # pretrained = True will initialize the model with parameters learned from ImageNet\n",
        "\n",
        "# Last fully-connected layer of VGG model (Layer #6)\n",
        "LAST_CONNECTED_LAYER = 6\n",
        "\n",
        "# Choose to freeze or unfreeze gradients of the model parameters during the training process\n",
        "## If feature extraction is on, the model's gradients will be computed and updated during backpropagation\n",
        "set_gradient_requirements( ImageClassifier, FEATURE_EXTRACTION_ON )\n",
        "\n",
        "# Number of input features to model's forward method\n",
        "numInputFeatures = ImageClassifier.classifier[ LAST_CONNECTED_LAYER ].in_features\n",
        "\n",
        "# Change the dimension of the last layer to NUMBER_OF_CLASSES (in our case, 2)\n",
        "ImageClassifier.classifier[ LAST_CONNECTED_LAYER ] = nn.Linear( numInputFeatures, NUMBER_OF_CLASSES )\n",
        "\n",
        "# Move the model to our device\n",
        "ImageClassifier.to( RuntimeDevice )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dusu1rXfmZHX"
      },
      "source": [
        "##Step 4: Optimization Tools\n",
        "\n",
        "In deep learning, we use loss metrics to evalute how close between the predicted label and the grouth truth. A smaller loss means a better performance. \n",
        "<br/>\n",
        "<br/>\n",
        "To minimize the loss at each time step, we will use the optimizer to compute the gradients and backpropagate through the network.\n",
        "<br/>\n",
        "<br/>\n",
        "Here we will use stochastic gradient descent as our optimizer and cross entropy as our loss metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1tLJLckkv1O"
      },
      "source": [
        "# Create the ModelOptimizer (we will be using Stochastic Gradient Descent)\n",
        "ModelOptimizer = optim.SGD( ImageClassifier.parameters(), \n",
        "                            lr = 0.001, # Play with lr for the best accuracy!!\n",
        "                            momentum = 0.9 ) \n",
        "\n",
        "# We will be using Cross-Entropy as our LossFunction\n",
        "LossFunction = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoZoE0ngofqJ"
      },
      "source": [
        "##Step 5: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71GDiMFkoiyU"
      },
      "source": [
        "## Function to train the model ## \n",
        "\n",
        "def train_model( model, dataloaders, criterion, optimizer, num_epochs ):\n",
        "\n",
        "    '''\n",
        "    Function to train a model using particular datasets, optimizer, and loss function\n",
        "\n",
        "    Args:\n",
        "    - model: a pre-defined neural network model\n",
        "    - dataloaders: a dictionary containing the training and validation data loaders\n",
        "    - criterion: the loss function used to measure the error of the model's output\n",
        "    - optimizer: the optimization algorithm used to adjust the model's parameters\n",
        "    - num_epochs: the number of times the entire dataset is passed through the model during training \n",
        "\n",
        "    Returns:\n",
        "    - model: the trained model\n",
        "    '''\n",
        "    \n",
        "    # Process startTime\n",
        "    startTime = time.time()\n",
        "\n",
        "    # Validation Accuracy History - % of correctly classified images at \n",
        "    # the end of each training epoch\n",
        "    accuracyLog = []\n",
        "    \n",
        "    # Highest model accuracy and set of model weights\n",
        "    bestModelWeights = copy.deepcopy( model.state_dict() )\n",
        "    highestAccuracy = 0.0\n",
        "\n",
        "    # Training Epochs\n",
        "    for currentEpoch in range(1, (NUMBER_OF_EPOCHS + 1) ):\n",
        "\n",
        "      # Log currentEpoch to console\n",
        "\n",
        "      logText = 'Epoch {}/{}'.format(currentEpoch, NUMBER_OF_EPOCHS)\n",
        "      print( logText )\n",
        "\n",
        "      print( '-' * len( logText ) ) # Number of dashes changes with text length\n",
        "\n",
        "      # Each epoch has a training and validation phase\n",
        "      PHASES = ('Training', 'Validation')\n",
        "\n",
        "      # Reset the currentFolder to trainingData in each epoch\n",
        "      currentFolder = 'trainingData'\n",
        "      \n",
        "      # Toggle between training phase and validation phase\n",
        "      for currentPhase in PHASES:\n",
        "          \n",
        "          # If we are in the training phase, set the model to training mode\n",
        "          if currentPhase == 'Training':\n",
        "              model.train()\n",
        "\n",
        "          # Otherwise, set the model to evaluation mode\n",
        "          else:\n",
        "              model.eval()\n",
        "              currentFolder = 'validationData' # Toggle currentFolder to validationData\n",
        "\n",
        "          # Continually track the number of correct predictions\n",
        "          # and the average loss of the model on the trainingData\n",
        "          numCorrect, runningLoss = 0, 0.0\n",
        "\n",
        "          # Iterate through the datasets\n",
        "          for modelInputs, targetOutput in dataloaders[ currentFolder ]:\n",
        "              \n",
        "              # Write the inputs and outputs to the RuntimeDevice\n",
        "              modelInputs, targetOutput = modelInputs.to( RuntimeDevice ), targetOutput.to( RuntimeDevice )\n",
        "\n",
        "              # Zero the parameter gradients at the beginning of each iteration \n",
        "              ModelOptimizer.zero_grad()\n",
        "\n",
        "              # Move our model forwards\n",
        "              # Track history if we are in the training phase (but not in the evalution phase)\n",
        "              with torch.set_grad_enabled( currentPhase == 'Training' ):\n",
        "                  \n",
        "                  # Obtain model outputs\n",
        "                  modelOutputs = model( modelInputs )\n",
        "\n",
        "                  # Update the LossFunction and modelPredictions\n",
        "                  LossFunction = criterion( modelOutputs, targetOutput )\n",
        "                  _, modelPredictions = torch.max( modelOutputs, 1 )\n",
        "\n",
        "                  # If we are in the training phase, move the LossFunction backwards and optimize\n",
        "                  if currentPhase == 'Training':\n",
        "                      LossFunction.backward()\n",
        "                      ModelOptimizer.step()\n",
        "\n",
        "              # Update our runningLoss and our number of correct predictions\n",
        "              runningLoss += LossFunction.item() * modelInputs.size(0)\n",
        "              numCorrect += torch.sum( modelPredictions == targetOutput.data)\n",
        "\n",
        "          # The loss over the epoch is the loss so far / the size of the dataset\n",
        "          epochLoss = runningLoss / len( dataloaders[ currentFolder ].dataset )\n",
        "\n",
        "          # The epoch accuracy is the number of correct predictions / the size of the dataset\n",
        "          epochAccuracy = numCorrect.double() / len( dataloaders[ currentFolder ].dataset )\n",
        "\n",
        "          # Print to console\n",
        "          print( '{} | Loss: {:.4f} Accuracy: {:.4f}'.format( currentPhase, epochLoss, epochAccuracy ) )\n",
        "\n",
        "          # If we are in the validation phase, deep copy the model\n",
        "          if currentPhase == 'Validation':\n",
        "\n",
        "            # Update the highestAccuracy and bestModelWeights if we have encountered bettter accuracy\n",
        "            if epochAccuracy > highestAccuracy:\n",
        "              highestAccuracy = epochAccuracy\n",
        "              bestModelWeights = copy.deepcopy( model.state_dict() )\n",
        "          \n",
        "            # Add the epoch's accuracy to the accuracyLog\n",
        "            accuracyLog.append( epochAccuracy )\n",
        "\n",
        "    # Total elapsedTime\n",
        "    elapsedTime = time.time() - startTime\n",
        "\n",
        "    # Log process time and model performance to console\n",
        "    print('\\n\\nTraining complete in {:.0f}m {:.0f}s!'.format( elapsedTime // 60, elapsedTime % 60 ) )\n",
        "    print('Highest validation accuracy: {:.4f}%'.format( highestAccuracy * 100 ) )\n",
        "\n",
        "    # Load the bestModelWeights\n",
        "    model.load_state_dict( bestModelWeights )\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6NmF-5bpeWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a01c839-0106-4e7f-8236-937ba46f65f4"
      },
      "source": [
        "## Fine-Tune the ImageClassifier model ##\n",
        "\n",
        "ImageClassifier = train_model( model = ImageClassifier, \n",
        "                               dataloaders = ImageDataLoaders, \n",
        "                               criterion = LossFunction, \n",
        "                               optimizer = ModelOptimizer, \n",
        "                               num_epochs = NUMBER_OF_EPOCHS )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "----------\n",
            "Training Loss: 0.6198 Acc: 0.6417\n",
            "Validation Loss: 0.5250 Acc: 0.7600\n",
            "\n",
            "Epoch 2/25\n",
            "----------\n",
            "Training Loss: 0.4665 Acc: 0.8233\n",
            "Validation Loss: 0.4185 Acc: 0.8200\n",
            "\n",
            "Epoch 3/25\n",
            "----------\n",
            "Training Loss: 0.4185 Acc: 0.8100\n",
            "Validation Loss: 0.3753 Acc: 0.8450\n",
            "\n",
            "Epoch 4/25\n",
            "----------\n",
            "Training Loss: 0.3488 Acc: 0.8483\n",
            "Validation Loss: 0.3501 Acc: 0.8550\n",
            "\n",
            "Epoch 5/25\n",
            "----------\n",
            "Training Loss: 0.3522 Acc: 0.8567\n",
            "Validation Loss: 0.3309 Acc: 0.8700\n",
            "\n",
            "Epoch 6/25\n",
            "----------\n",
            "Training Loss: 0.3614 Acc: 0.8467\n",
            "Validation Loss: 0.3218 Acc: 0.8750\n",
            "\n",
            "Epoch 7/25\n",
            "----------\n",
            "Training Loss: 0.3290 Acc: 0.8617\n",
            "Validation Loss: 0.3116 Acc: 0.8750\n",
            "\n",
            "Epoch 8/25\n",
            "----------\n",
            "Training Loss: 0.3395 Acc: 0.8483\n",
            "Validation Loss: 0.3026 Acc: 0.8800\n",
            "\n",
            "Epoch 9/25\n",
            "----------\n",
            "Training Loss: 0.3315 Acc: 0.8567\n",
            "Validation Loss: 0.2949 Acc: 0.8850\n",
            "\n",
            "Epoch 10/25\n",
            "----------\n",
            "Training Loss: 0.3345 Acc: 0.8550\n",
            "Validation Loss: 0.2902 Acc: 0.8800\n",
            "\n",
            "Epoch 11/25\n",
            "----------\n",
            "Training Loss: 0.3339 Acc: 0.8467\n",
            "Validation Loss: 0.2922 Acc: 0.8750\n",
            "\n",
            "Epoch 12/25\n",
            "----------\n",
            "Training Loss: 0.3052 Acc: 0.8767\n",
            "Validation Loss: 0.2784 Acc: 0.8900\n",
            "\n",
            "Epoch 13/25\n",
            "----------\n",
            "Training Loss: 0.3014 Acc: 0.8683\n",
            "Validation Loss: 0.2770 Acc: 0.8950\n",
            "\n",
            "Epoch 14/25\n",
            "----------\n",
            "Training Loss: 0.2914 Acc: 0.8650\n",
            "Validation Loss: 0.2776 Acc: 0.8850\n",
            "\n",
            "Epoch 15/25\n",
            "----------\n",
            "Training Loss: 0.3323 Acc: 0.8467\n",
            "Validation Loss: 0.2743 Acc: 0.8900\n",
            "\n",
            "Epoch 16/25\n",
            "----------\n",
            "Training Loss: 0.2948 Acc: 0.8783\n",
            "Validation Loss: 0.2810 Acc: 0.8850\n",
            "\n",
            "Epoch 17/25\n",
            "----------\n",
            "Training Loss: 0.2797 Acc: 0.8917\n",
            "Validation Loss: 0.2715 Acc: 0.8850\n",
            "\n",
            "Epoch 18/25\n",
            "----------\n",
            "Training Loss: 0.3187 Acc: 0.8300\n",
            "Validation Loss: 0.2663 Acc: 0.8900\n",
            "\n",
            "Epoch 19/25\n",
            "----------\n",
            "Training Loss: 0.3199 Acc: 0.8717\n",
            "Validation Loss: 0.2792 Acc: 0.8800\n",
            "\n",
            "Epoch 20/25\n",
            "----------\n",
            "Training Loss: 0.3071 Acc: 0.8550\n",
            "Validation Loss: 0.2576 Acc: 0.9050\n",
            "\n",
            "Epoch 21/25\n",
            "----------\n",
            "Training Loss: 0.2944 Acc: 0.8750\n",
            "Validation Loss: 0.2610 Acc: 0.8950\n",
            "\n",
            "Epoch 22/25\n",
            "----------\n",
            "Training Loss: 0.2767 Acc: 0.8917\n",
            "Validation Loss: 0.2640 Acc: 0.8850\n",
            "\n",
            "Epoch 23/25\n",
            "----------\n",
            "Training Loss: 0.2986 Acc: 0.8800\n",
            "Validation Loss: 0.2546 Acc: 0.8900\n",
            "\n",
            "Epoch 24/25\n",
            "----------\n",
            "Training Loss: 0.2935 Acc: 0.8783\n",
            "Validation Loss: 0.2523 Acc: 0.8900\n",
            "\n",
            "Epoch 25/25\n",
            "----------\n",
            "Training Loss: 0.2819 Acc: 0.8717\n",
            "Validation Loss: 0.2586 Acc: 0.8850\n",
            "\n",
            "Training complete in 7m 4s!\n",
            "Best Validation Accuracy: 90.5000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypB6wG--eevW"
      },
      "source": [
        "## Now test the model using our testData ##\n",
        "\n",
        "# load test dataset and create test dataloader as in step 2\n",
        "\n",
        "# Add the testData transforms to our DataTransforms HashMap, and set it equal to our trainingData transforms\n",
        "DataTransforms[ 'testData' ] = DataTransforms[ 'trainingData' ]\n",
        "\n",
        "# Create our test dataset\n",
        "ImageDatasets[ 'testData' ] = datasets.ImageFolder( get_folder_path( 'testData' ),\n",
        "                                                    DataTransforms['testData'] )\n",
        "\n",
        "# Create our test DataLoader\n",
        "\n",
        "ImageDataLoaders[ 'testData' ] = torch.utils.data.DataLoader( ImageDatasets['testData'],\n",
        "                                                              batch_size = BATCH_SIZE,\n",
        "                                                              shuffle = True,\n",
        "                                                              num_workers = 4 )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function to test our model (very similar to train_model) ##\n",
        "\n",
        "def test_model( model, dataloader ):\n",
        "  \n",
        "  '''\n",
        "  Function to test the performance of a trained model on a test dataset\n",
        "\n",
        "  Arguments:\n",
        "  - model (nn.Module): trained image classification model to be tested\n",
        "  - dataloader (DataLoader): PyTorch DataLoader object for the test dataset\n",
        "\n",
        "  Returns:\n",
        "  - testAccuracy (float): the classification accuracy of the model\n",
        "  '''\n",
        "\n",
        "  # First, we set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Track the # of correct predictions and the # of total predictions\n",
        "  numCorrect, numPredictions = 0, 0\n",
        "\n",
        "\n",
        "  with torch.no_grad(): # Gradients are not needed in inference/validation\n",
        "\n",
        "    # Iterate over the test dataset   \n",
        "    for modelInputs, targetOutput in dataloader:\n",
        "\n",
        "      # Move the modelInputs and targetOutputs to the RuntimeDevice\n",
        "      modelInputs, targetOutput = modelInputs.to( RuntimeDevice ), targetOutput.to( RuntimeDevice )\n",
        "\n",
        "      # Predict!\n",
        "      modelOutput = model( modelInputs )\n",
        "      _, modelPrediction = torch.max( modelOutput, 1 )\n",
        "\n",
        "      # Update the numCorrect and numPredictions\n",
        "      numCorrect += (modelPrediction == targetOutput).sum().item()\n",
        "      numPredictions += targetOutput.size(0)\n",
        "\n",
        "  # Calculate testAccuracy ( return object )\n",
        "  testAccuracy = numCorrect / numPredictions\n",
        "\n",
        "  # Log testAccuracy to console\n",
        "  print( 'Test Accuracy: {:.2f}%'.format( testAccuracy * 100 ) )\n",
        "\n",
        "  # Final return\n",
        "  #return testAccuracy"
      ],
      "metadata": {
        "id": "rSAZHE8jzp_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's Drive! ##\n",
        "\n",
        "test_model( model = ImageClassifier,\n",
        "            dataloader = ImageDataLoaders['testData'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1S3IYVr4oNY",
        "outputId": "30ff054b-d27f-4b20-8db7-44c8a3bd128d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 85.50%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.855"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}